{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem No. 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Max_Size(words_dict):\n",
    "    '''\n",
    "        returns max size and index of word in 'words_dict' \n",
    "    '''\n",
    "    max_size = 0\n",
    "    max_index = 0\n",
    "    for i in range(0, len(words_dict)):\n",
    "        if (len(words_dict[i]) > max_size):\n",
    "            max_size = len(words_dict[i])\n",
    "            max_index = i\n",
    "    return max_size, max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Match_Word(word, dict_):\n",
    "    '''\n",
    "        return True if 'word' is found in 'dict_'\n",
    "    '''\n",
    "    match = False\n",
    "    \n",
    "    for i in range(0, len(dict_)):\n",
    "        if(word == dict_[i]):\n",
    "            match = True\n",
    "            break\n",
    "    \n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxMatch (sentence, words_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        sentence:   a string that is to be tokenized using max match algorithm\n",
    "        words_dict: the list of words i.e. dictionary\n",
    "    Output:\n",
    "        words_match_list:  The list of words extracted after applying max match\n",
    "    '''\n",
    "    tokenized_sentence = None\n",
    "    max_word_size, max_word_indx = Max_Size(words_dict)\n",
    "    \n",
    "    words_match_list = []\n",
    "    \n",
    "    # print('Max_Word_Size:\\t\\t'+str(max_word_size)+\"\\t\\t Max_Size_Word:\\t\\t\"+str(words_dict[max_word_indx]) + \"\\tindex:\\t\\t\" + str(max_word_indx))\n",
    "    \n",
    "    a = 0\n",
    "    for i in range(0, len(sentence)):\n",
    "        if(a < len(sentence)):\n",
    "            flag_match_found = False\n",
    "            max_word = None\n",
    "            match_idx = 0\n",
    "\n",
    "            for j in range(0, max_word_size):\n",
    "\n",
    "                itr_word = sentence[a:(a+j+1)]\n",
    "\n",
    "                if(Match_Word(itr_word, words_dict)):\n",
    "                    max_word = itr_word\n",
    "                    flag_match_found = True\n",
    "                    match_idx = j\n",
    "\n",
    "            if (flag_match_found):\n",
    "                words_match_list.append(max_word)\n",
    "                a = a+match_idx+1\n",
    "            else:\n",
    "                words_match_list.append(sentence[a])\n",
    "                a += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return words_match_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MED(source, target):\n",
    "    '''\n",
    "    input:\n",
    "        source: a string\n",
    "        target: a string\n",
    "    output:\n",
    "        out: a dict object which contain following items\n",
    "            'D': The number of deletions required to convert source to target\n",
    "            'I': The number of insertions required to convert source to target\n",
    "            'S': The number of substitutions required to convert source to target\n",
    "            'MED': The minimum edit distance to convert source to target\n",
    "    '''\n",
    "    i_cost = 1\n",
    "    d_cost = 1\n",
    "    s_cost = 2\n",
    "    \n",
    "    n = len(source)\n",
    "    m = len(target)\n",
    "    \n",
    "    Dist = np.zeros((n+1, m+1, 1)).astype('uint8') # n,m,0 = total cost;\n",
    "    Ops = np.zeros((n+1, m+1, 3)).astype('uint8') # n,m,1 = # of insertions; n,m,0 = # of deletions; n,m,2 = # of substitutions\n",
    "    \n",
    "    #initilizations\n",
    "    for i in range(1, n+1):\n",
    "        Dist[i, 0, 0] = Dist[i-1, 0, 0] + d_cost\n",
    "        Ops[i, 0, 0] = 1\n",
    "    \n",
    "    for i in range(1, m+1):\n",
    "        Dist[0, i, 0] = Dist[0, i-1, 0] + i_cost\n",
    "        Ops[0, i, 1] = 1\n",
    "        \n",
    "    #recurrence\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            costs = [0]*3\n",
    "            costs[0] = Dist[i-1, j, 0] + d_cost #deletion\n",
    "            costs[1] = Dist[i, j-1, 0] + i_cost #insertion\n",
    "            \n",
    "            if(source[i-1] == target[j-1]): #sub\n",
    "                costs[2] = Dist[i-1, j-1, 0]\n",
    "            else:\n",
    "                costs[2] = Dist[i-1, j-1, 0] + s_cost\n",
    "            \n",
    "            Dist[i, j, 0] = min(costs)\n",
    "            \n",
    "            minval = min(costs)\n",
    "            for a in range(0, len(costs)):\n",
    "                if (costs[a] == minval):\n",
    "                    Ops[i, j, a] = 1\n",
    "                    #print(i,j)\n",
    "            \n",
    "    #print(Dist)\n",
    "    #i = 4\n",
    "    #print(Ops[n-i, m-i])\n",
    "    #print(Ops[n-i-1, m-i])\n",
    "    #print(Ops[n-i, m-i-1])\n",
    "    #print(Ops[n-i-1, m-i-1])\n",
    "    \n",
    "    #back-track\n",
    "    a = n\n",
    "    b = m\n",
    "    \n",
    "    t_s = 0\n",
    "    t_d = 0\n",
    "    t_i = 0\n",
    "    \n",
    "    while((a != 0) or (b != 0)):\n",
    "        #print(a, b, Dist[a, b, 0], Ops[a, b])\n",
    "        costs = []\n",
    "        op = []\n",
    "        if(Ops[a, b, 2] == 1):\n",
    "            costs.append(Dist[a, b, 0])\n",
    "            op.append(\"s\")\n",
    "        if(Ops[a, b, 0] == 1):\n",
    "            costs.append(Dist[a, b, 0])\n",
    "            op.append(\"d\")\n",
    "        if(Ops[a, b, 1] == 1):\n",
    "            costs.append(Dist[a, b, 0])\n",
    "            op.append(\"i\")\n",
    "        \n",
    "        minval = min(costs)\n",
    "        indx = costs.index(minval)\n",
    "        #print(indx, costs)\n",
    "        if (op[indx] == 's'):\n",
    "            if(Dist[a, b, 0] != Dist[a-1, b-1, 0]):\n",
    "                t_s += 1\n",
    "                #print(Dist[a, b, 0], Dist[a-1, b-1, 0])\n",
    "            a -=1\n",
    "            b -=1\n",
    "        elif (op[indx] == 'd'):\n",
    "            a -=1\n",
    "            t_d += 1\n",
    "        elif (op[indx] == 'i'):\n",
    "            b -=1\n",
    "            t_i += 1\n",
    "    \n",
    "    out = {\n",
    "        'D': t_d,\n",
    "        'I': t_i,\n",
    "        'S': t_s,\n",
    "        'MED': Dist[n, m, 0]\n",
    "    }\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_based (sentence1, sentence2):\n",
    "    '''\n",
    "    input:\n",
    "        sentence1: a string\n",
    "        sentence2: a string\n",
    "    output:\n",
    "        out: a dict object which contain following items\n",
    "            'total_D': The number of deletions required to convert sentence1 to sentence2\n",
    "            'total_I': The number of insertions required to convert sentence1 to sentence2\n",
    "            'total_S': The number of substitutions required to convert sentence1 to sentence2\n",
    "            'total_MED': The minimum edit distance to convert sentence1 to sentence2\n",
    "    '''\n",
    "    len1 = len(sentence1)\n",
    "    len2 = len(sentence2)\n",
    "    \n",
    "    if (len1 > len2):\n",
    "        len_s = len2\n",
    "        len_h = len1\n",
    "    elif(len2 > len1):\n",
    "        len_s = len1\n",
    "        len_h = len2\n",
    "    else:\n",
    "        len_s = len1\n",
    "        len_h = len2\n",
    "    \n",
    "    total_dist = 0\n",
    "    total_sub = 0\n",
    "    total_ins = 0\n",
    "    total_del = 0\n",
    "    for i in range(0, len_s):\n",
    "        #print(i)\n",
    "        outstruc = MED(sentence1[i], sentence2[i])\n",
    "        total_dist += outstruc['MED']\n",
    "        total_sub += outstruc['S']\n",
    "        total_ins += outstruc['I']\n",
    "        total_del += outstruc['D']\n",
    "    \n",
    "    if(len_s != len_h):\n",
    "        if(len2 == len_s):\n",
    "            #delete remaining words of sentence1\n",
    "            words_toremove = sentence1[len2:]\n",
    "        else:\n",
    "            #delete remaining words of sentence2\n",
    "            words_toremove = sentence2[len1:]\n",
    "        for i in words_toremove:\n",
    "            total_dist += len(i)\n",
    "            total_del += len(i) #we can use insertion as well, our choice\n",
    "    \n",
    "    out = {\n",
    "        'total_MED': total_dist,\n",
    "        'total_I': total_ins,\n",
    "        'total_S': total_sub,\n",
    "        'total_D': total_del\n",
    "    }\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WER(S, D, I, N):\n",
    "    '''\n",
    "    input:\n",
    "        S: number of substitutions\n",
    "        D: number of deletions\n",
    "        I: number of insertions\n",
    "        N: number of words in correct sentence\n",
    "    '''\n",
    "    return (S+D+I)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_based(sentence1, sentence2): #assuming sentence2 is the target sentence, i.e. correct sentence\n",
    "    '''\n",
    "    input:\n",
    "        sentence1: a string\n",
    "        sentence2: a string\n",
    "    output:\n",
    "        out: a dict object which contain following items\n",
    "            'D': The number of deletions required to convert sentence1 to sentence2\n",
    "            'I': The number of insertions required to convert sentence1 to sentence2\n",
    "            'S': The number of substitutions required to convert sentence1 to sentence2\n",
    "            'MED': The minimum edit distance to convert sentence1 to sentence2\n",
    "            'WER': Word error rate\n",
    "    '''\n",
    "    out = MED(sentence1, sentence2)\n",
    "    out['WER'] = WER(out['S'], out['D'], out['I'], len(sentence2))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_WER(source_set, target_set):\n",
    "    '''\n",
    "    input:\n",
    "        source_set: the list of strings containing the source strings\n",
    "        target_set: the list of strings containing the target strings\n",
    "    output:\n",
    "        avg: the average of Word error rate for whole input set\n",
    "    '''\n",
    "    wer = 0\n",
    "    for i in range(0, len(source_set)):\n",
    "        wer += word_based(source_set[i], target_set[i])['WER']\n",
    "    \n",
    "    avg = wer/len(source_set)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem No. 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Str2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2vec_word_based_count(str1, str2):\n",
    "    '''\n",
    "    input:\n",
    "        \n",
    "    '''\n",
    "    vec_words = list(set(str1+str2))\n",
    "    \n",
    "    vec1 = [0] * len(vec_words)\n",
    "    vec2 = [0] * len(vec_words)\n",
    "    for i in str1:\n",
    "        vec1[vec_words.index(i)] += 1\n",
    "    \n",
    "    for i in str2:\n",
    "        vec2[vec_words.index(i)] += 1\n",
    "    \n",
    "    return vec1, vec2, vec_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2vec_word_based_freq(str1, str2):\n",
    "    vec1, vec2, vec_words = str2vec_word_based_count(str1, str2)\n",
    "    \n",
    "    return (np.array(vec1)/len(str1)).tolist(), (np.array(vec2)/len(str2)).tolist(), vec_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2vec_char_based_count(str1, str2):\n",
    "    \n",
    "    vec_words = list(set(str1+str2))\n",
    "    vec_chars = []\n",
    "    for i in range(0, len(vec_words)):\n",
    "        for j in vec_words[i]:\n",
    "            vec_chars.append(j)\n",
    "    vec_chars = list(set(vec_chars))\n",
    "    \n",
    "    vec1 = [0] * len(vec_chars)\n",
    "    vec2 = [0] * len(vec_chars)\n",
    "    for i in range(0, len(str1)):\n",
    "        for j in str1[i]:\n",
    "            vec1[vec_chars.index(j)] += 1\n",
    "    \n",
    "    for i in range(0, len(str2)):\n",
    "        for j in str2[i]:\n",
    "            vec2[vec_chars.index(j)] += 1\n",
    "    \n",
    "    \n",
    "    return vec1, vec2, vec_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2vec_char_based_freq(str1, str2):\n",
    "    vec1, vec2, vec_words = str2vec_char_based_count(str1, str2)\n",
    "    \n",
    "    return (np.array(vec1)/len(str1)).tolist(), (np.array(vec2)/len(str2)).tolist(), vec_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bigram(str_):\n",
    "    bigram = []\n",
    "    \n",
    "    if ( str(type(str_)) == \"<class 'list'>\"):\n",
    "        for i in range(0, len(str_)):\n",
    "            if i == 0:\n",
    "                bigram.append(\"-\"+str_[0][0])\n",
    "            else:\n",
    "                bigram.append(str_[i-1][len(str_[i-1])-1]+str_[i][0])\n",
    "            for j in range(1, len(str_[i])):\n",
    "                bigram.append(str_[i][j-1]+str_[i][j])\n",
    "        bigram.append(str_[len(str_)-1][len(str_[len(str_)-1])-1]+\"-\")\n",
    "            \n",
    "    elif(str(type(str_)) == \"<class 'str'>\"):\n",
    "        bigram.append(\"-\"+str_[0])\n",
    "        for j in range(1, len(str_)):\n",
    "                bigram.append(str_[j-1]+str_[j])\n",
    "        bigram.append(str_[len(str_)-1]+\"-\")\n",
    "        \n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(str1, str2, base, measure):\n",
    "    if (base == 'char'):\n",
    "        if (measure == 'freq'):\n",
    "            return str2vec_char_based_freq(str1, str2)\n",
    "        elif (measure == 'count'):\n",
    "            return str2vec_char_based_count(str1, str2)\n",
    "        else:\n",
    "            assert False, \"measure value UnExpected\"\n",
    "            \n",
    "    elif (base == 'word'):\n",
    "        if (measure == 'freq'):\n",
    "            return str2vec_word_based_freq(str1, str2)\n",
    "        elif (measure == 'count'):\n",
    "            return str2vec_word_based_count(str1, str2)\n",
    "        else:\n",
    "            assert False, \"measure value UnExpected\"\n",
    "    else:\n",
    "        assert False, \"base value UnExpected\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(str1, str2, base = 'char', measure = 'freq'):\n",
    "    '''\n",
    "    input:\n",
    "        str1: the text string\n",
    "        str2: the text string\n",
    "        base: the base on which vector will be made, char/word\n",
    "        measure: the measure on which the values will be filled in vector, count/freq\n",
    "    output:\n",
    "        the computed distance\n",
    "    '''\n",
    "    vec1, vec2, vec_list = validation(str1, str2, base, measure)\n",
    "    \n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    return np.sqrt(np.sum(np.power((vec1-vec2), 2))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(str1, str2, base = 'char', measure = 'freq'):\n",
    "    '''\n",
    "    input:\n",
    "        str1: the text string\n",
    "        str2: the text string\n",
    "        base: the base on which vector will be made, char/word\n",
    "        measure: the measure on which the values will be filled in vector, count/freq\n",
    "    output:\n",
    "        the computed distance\n",
    "    '''\n",
    "    vec1, vec2, vec_list = validation(str1, str2, base, measure)\n",
    "    \n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    return np.sum(np.absolute(vec1-vec2)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chebychev_distance(str1, str2, base = 'char', measure = 'freq'):\n",
    "    '''\n",
    "    input:\n",
    "        str1: the text string\n",
    "        str2: the text string\n",
    "        base: the base on which vector will be made, char/word\n",
    "        measure: the measure on which the values will be filled in vector, count/freq\n",
    "    output:\n",
    "        the computed distance\n",
    "    '''\n",
    "    vec1, vec2, vec_list = validation(str1, str2, base, measure)\n",
    "    \n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    sub = np.absolute(vec1-vec2)\n",
    "    \n",
    "    return np.amax(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(str1, str2, base = 'char', measure = 'freq'):\n",
    "    '''\n",
    "    input:\n",
    "        str1: the text string\n",
    "        str2: the text string\n",
    "        base: the base on which vector will be made, char/word\n",
    "        measure: the measure on which the values will be filled in vector, count/freq\n",
    "    output:\n",
    "        the computed similarity\n",
    "    '''\n",
    "    vec1, vec2, vec_list = validation(str1, str2, base, measure)\n",
    "    \n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    dot_ = np.dot(vec1, vec2.T)\n",
    "    similarity = dot_/((np.sqrt(np.sum(np.power(vec1, 2)))) * (np.sqrt(np.sum(np.power(vec2, 2)))))\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(str1, str2, base = 'char', measure = 'freq'):\n",
    "    '''\n",
    "    input:\n",
    "        str1: the text string\n",
    "        str2: the text string\n",
    "        base: the base on which vector will be made, char/word\n",
    "        measure: the measure on which the values will be filled in vector, count/freq\n",
    "    output:\n",
    "        the computed distance\n",
    "    '''\n",
    "    return 1 - cosine_similarity(str1, str2, base, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(str1, str2, base = 'char'):\n",
    "    '''\n",
    "    input:\n",
    "        str1: the text string\n",
    "        str2: the text string\n",
    "        base: the base on which vector will be made, char/word/bigram\n",
    "    output:\n",
    "        the computed similarity\n",
    "    '''\n",
    "    vec1 = []\n",
    "    vec2 = []\n",
    "    if (base == 'char'):\n",
    "        if ( str(type(str1)) == \"<class 'list'>\"):\n",
    "            strtmp = ''\n",
    "            for i in str1:\n",
    "                strtmp += i\n",
    "            vec1 = set(strtmp)\n",
    "        elif (str(type(str1)) == \"<class 'str'>\"):\n",
    "            vec1 = set(str1)\n",
    "        else:\n",
    "            assert False, \"Garbarrrr\"\n",
    "\n",
    "        if ( str(type(str2)) == \"<class 'list'>\"):\n",
    "            strtmp = ''\n",
    "            for i in str2:\n",
    "                strtmp += i\n",
    "            vec2 = set(strtmp)\n",
    "        elif (str(type(str2)) == \"<class 'str'>\"):\n",
    "            vec2 = set(str2)\n",
    "        else:\n",
    "            assert False, \"Garbarrrr\"\n",
    "    elif (base == 'word'):\n",
    "        if ( str(type(str1)) == \"<class 'list'>\"):\n",
    "            vec1 = set(str1)\n",
    "        elif ( str(type(str1)) == \"<class 'str'>\"):\n",
    "            vec1 = {str1}\n",
    "        else:\n",
    "            assert False, \"Garbarrrr\"\n",
    "        \n",
    "        if ( str(type(str2)) == \"<class 'list'>\"):\n",
    "            vec2 = set(str2)\n",
    "        elif ( str(type(str2)) == \"<class 'str'>\"):\n",
    "            vec2 = {str2}\n",
    "        else:\n",
    "            assert False, \"Garbarrrr\"\n",
    "    elif (base == 'bigram'):\n",
    "        vec1 = set(to_bigram(str1))\n",
    "        vec2 = set(to_bigram(str2))\n",
    "    else:\n",
    "        assert False, \"Garbarrrr\"\n",
    "    \n",
    "    return len(vec1&vec2) / len(vec1|vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(str1, str2, base = 'char'):\n",
    "    '''\n",
    "    input:\n",
    "        str1: the text string\n",
    "        str2: the text string\n",
    "        base: the base on which vector will be made, char/word/bigram\n",
    "    output:\n",
    "        the computed distance\n",
    "    '''\n",
    "    return 1 - jaccard_similarity(str1, str2, base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_same_length_str(str1, str2):\n",
    "    count = 0\n",
    "    for i in range(0, len(str1)):\n",
    "        if (str1[i] != str2[i]):\n",
    "            count += 1\n",
    "    return count    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_less_length_str(str1, str2):\n",
    "    count_list = []\n",
    "    diff = len(str2) - len(str1)\n",
    "    for i in range(0, diff):\n",
    "        tempstr = \" \"*i\n",
    "        tempstr += str1\n",
    "        tempstr += \" \"*(diff-i)\n",
    "        count_list.append(hamming_same_length_str(tempstr, str2))\n",
    "    return min(count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_str(str1, str2):\n",
    "    if (len(str1) == len(str2)):\n",
    "        return hamming_same_length_str(str1, str2)\n",
    "    elif (len(str1) < len(str2)):\n",
    "        return hamming_less_length_str(str1, str2)\n",
    "    else:\n",
    "        return hamming_less_length_str(str2, str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_list_str_dist(input1, input2):\n",
    "    '''\n",
    "    input:\n",
    "        input1: string or list of strings\n",
    "        input2: string or list of strings\n",
    "    output:\n",
    "        the hamming distance\n",
    "    '''\n",
    "    if ( str(type(input1)) == \"<class 'str'>\"):\n",
    "        return hamming_str(input1, input2)\n",
    "    else:\n",
    "        dist_sum = 0\n",
    "        if (len(input1) == len(input2)):\n",
    "            for i in range(0, len(input1)):\n",
    "                dist_sum += hamming_str(input1[i], input2[i])\n",
    "            return dist_sum\n",
    "        else:\n",
    "            assert False, \"Lists with different size, Kamaaal h bai!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS_str(str1, str2):\n",
    "    n = len(str1)\n",
    "    m = len(str2)\n",
    "    \n",
    "    LCS = np.zeros((n+1, m+1, 1)).astype('uint8')\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            if(str1[i-1] == str2[j-1]):\n",
    "                LCS[i][j] = LCS[i-1][j-1]+1\n",
    "            else:\n",
    "                LCS[i][j] = max(LCS[i-1][j], LCS[i][j-1])\n",
    "    \n",
    "    a = n\n",
    "    b = m\n",
    "    sequence = \"\"\n",
    "    if  (str(type(str1)) == \"<class 'str'>\"):\n",
    "        sequence = \"\"\n",
    "    else:\n",
    "        sequence = []\n",
    "    \n",
    "    while(LCS[a][b][0] != 0):\n",
    "        if(str1[a-1] == str2[b-1]):\n",
    "            if  (str(type(str1)) == \"<class 'str'>\"):\n",
    "                sequence += str1[a-1]\n",
    "            else:\n",
    "                sequence.append(str1[a-1])\n",
    "            a -= 1\n",
    "            b -= 1\n",
    "        else:\n",
    "            if(LCS[a-1][b][0] == LCS[a][b][0]):\n",
    "                a -= 1\n",
    "            else:\n",
    "                b -= 1\n",
    "    out  = {}\n",
    "    out[\"size\"] = LCS[n][m][0]\n",
    "    out[\"sequence\"] = sequence[::-1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS (input1, input2, base = 'char'):\n",
    "    '''\n",
    "    input:\n",
    "        input1: string or list of strings\n",
    "        input2: string or list of strings\n",
    "    output:\n",
    "        out: a dict object containing,\n",
    "        'size' - the LCS size\n",
    "        'sequence' - the LCS\n",
    "    '''\n",
    "    if(base == 'char'):\n",
    "        if (str(type(input1)) == \"<class 'str'>\"):\n",
    "            return LCS_str(input1, input2)\n",
    "        else:\n",
    "            size = 0\n",
    "            sequence = []\n",
    "            if(len(input1) < len(input2)):\n",
    "                for i in range(0, len(input1)):\n",
    "                    temp = LCS_str(input1[i], input2[i])\n",
    "                    size += temp[\"size\"]\n",
    "                    sequence.append(temp[\"sequence\"])\n",
    "            else:\n",
    "                for i in range(0, len(input2)):\n",
    "                    temp = LCS_str(input1[i], input2[i])\n",
    "                    size += temp[\"size\"]\n",
    "                    sequence.append(temp[\"sequence\"])\n",
    "            out = {}\n",
    "            out[\"size\"] = size\n",
    "            out[\"sequence\"] = sequence\n",
    "            return out\n",
    "    else:\n",
    "        return LCS_str(input1, input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
