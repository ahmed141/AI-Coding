{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(text):\n",
    "    '''\n",
    "    Assumptions:\n",
    "        - I will deal abberviaions words as separte words e.g. Mr. Ahmed as 'Mr' and 'Ahmed'\n",
    "        - I will deal name with space within as seprate words e.g. Coca Cola as 'Coca' and 'Cola'\n",
    "        - I am assuming that my sentences/input text can only contain \" '.', ',', '?', and '!'. \n",
    "          however this concept can be extended in my code similarly as mentioned spatial characters are dealt.\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "        text - A string variable contains the text to be tokenized\n",
    "    returns:\n",
    "        words - list of strings, contains the list of tokenized words\n",
    "        \n",
    "    '''\n",
    "    words = text.replace('.',' . ').replace(',',' , ').replace('?', ' ? ').replace('!', ' ! ').split(' ')\n",
    "        \n",
    "    ept_count = 0\n",
    "    for i in range(0, len(words)):\n",
    "        if (words[i] == ''):\n",
    "            ept_count+=1\n",
    "    \n",
    "    # print(ept_count)\n",
    "    \n",
    "    for i in range(0, ept_count):\n",
    "        words.remove('')\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance(text, word, size = 3):\n",
    "    '''\n",
    "    input:\n",
    "        text - the sentece/ text to perform algorithm\n",
    "        word - the key / or the word to find\n",
    "        size - the size of window to lookup, set=3 as default\n",
    "    \n",
    "    return:\n",
    "        out - the result of concordance\n",
    "    '''\n",
    "    \n",
    "    words = extract_words(text)\n",
    "    \n",
    "    match = False\n",
    "    match_indexes = []\n",
    "    \n",
    "    for i in range(0, len(words)):\n",
    "        if (words[i] == word):\n",
    "            match_indexes.append(i)\n",
    "            match = True\n",
    "    \n",
    "    # now match_indexes contains the indexes where the word is found\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    if (match == True):\n",
    "        for i in range(0, len(match_indexes)):\n",
    "            match = []\n",
    "            pre = words[(match_indexes[i]-size):match_indexes[i]]\n",
    "            for a in range(0, len(pre)):\n",
    "                match.append(pre[a])\n",
    "                \n",
    "            match.append(words[match_indexes[i]])\n",
    "            \n",
    "            post = words[(match_indexes[i]+1):(match_indexes[i]+size+1)]\n",
    "            \n",
    "            for i in range(0, len(post)):\n",
    "                match.append(post[i])\n",
    "            \n",
    "            out.append(match)\n",
    "    else:\n",
    "        out = [\"word not found\"]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"This is a cat. This is a mat. This is a mouse. This is a ball. This is my cat and i like her very much\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "['is', 'a', 'cat', '.', 'This']\n",
      "['is', 'my', 'cat', 'and', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(\"OUTPUT:\\n\")\n",
    "for i in concordance(text1, 'cat', 2): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./concordance.txt')\n",
    "\n",
    "f = f.readlines()\n",
    "count  = 0\n",
    "for i in f:\n",
    "    f[count] = f[count].strip()\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_ = ''\n",
    "for i in range(0, len(f)):\n",
    "    str_ += f[i]\n",
    "    str_ += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'that was not what I was thinking what are you upto was I not thinking what I was upto why do you ask me what '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'I', 'was', 'thinking', 'what']\n",
      "['what', 'I', 'was', 'thinking', 'what', 'are', 'you', 'upto', 'was']\n",
      "['was', 'I', 'not', 'thinking', 'what', 'I', 'was', 'upto', 'why']\n",
      "['do', 'you', 'ask', 'me', 'what']\n"
     ]
    }
   ],
   "source": [
    "for i in concordance(str_, 'what', 4): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
