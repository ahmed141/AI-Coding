{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(text):\n",
    "    '''\n",
    "    Assumptions:\n",
    "        - I will deal abberviaions words as separte words e.g. Mr. Ahmed as 'Mr' and 'Ahmed'\n",
    "        - I will deal name with space within as seprate words e.g. Coca Cola as 'Coca' and 'Cola'\n",
    "        - I am assuming that my sentences/input text can only contain \" '.', ',', '?', and '!'. \n",
    "          however this concept can be extended in my code similarly as mentioned spatial characters are dealt.\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "        text - A string variable contains the text to be tokenized\n",
    "    returns:\n",
    "        words - list of strings, contains the list of tokenized words\n",
    "        \n",
    "    '''\n",
    "    words = text.replace('.',' . ').replace(',',' , ').replace('?', ' ? ').replace('!', ' ! ').split(' ')\n",
    "        \n",
    "    ept_count = 0\n",
    "    for i in range(0, len(words)):\n",
    "        if (words[i] == ''):\n",
    "            ept_count+=1\n",
    "    \n",
    "    \n",
    "    for i in range(0, ept_count):\n",
    "        words.remove('')\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_context(conc_list, word):\n",
    "    '''\n",
    "    This function returns that what was before and after the word in the list of strings\n",
    "    \n",
    "    inputs:\n",
    "        conc_list - the list of strings\n",
    "        word - the key OR the word to split list\n",
    "        \n",
    "    returns:\n",
    "        pre - the list of strings before 'word'\n",
    "        post - the list of strings after 'word'\n",
    "    '''\n",
    "    \n",
    "    centr = 0\n",
    "    \n",
    "    for i in range(0, len(conc_list)):\n",
    "        if (conc_list[i] == word):\n",
    "            centr = i\n",
    "            break\n",
    "    \n",
    "    pre = list(conc_list[:centr])\n",
    "    post = list(conc_list[(centr+1):])\n",
    "    \n",
    "    return pre, post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance(text, word, size = 3):\n",
    "    '''\n",
    "    input:\n",
    "        text - the sentece/ text to perform algorithm\n",
    "        word - the key / or the word to find\n",
    "        size - the size of window to lookup, set=3 as default\n",
    "    \n",
    "    return:\n",
    "        out - the result of concordance\n",
    "        words - the list of tokenized words\n",
    "    '''\n",
    "    \n",
    "    words = extract_words(text)\n",
    "    \n",
    "    match = False\n",
    "    match_indexes = []\n",
    "    \n",
    "    for i in range(0, len(words)):\n",
    "        if (words[i] == word):\n",
    "            match_indexes.append(i)\n",
    "            match = True\n",
    "    \n",
    "    # now match_indexes contains the indexes where the word is found\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    if (match == True):\n",
    "        for i in range(0, len(match_indexes)):\n",
    "            match = []\n",
    "            pre = words[(match_indexes[i]-size):match_indexes[i]]\n",
    "            for a in range(0, len(pre)):\n",
    "                match.append(pre[a])\n",
    "                \n",
    "            match.append(words[match_indexes[i]])\n",
    "            \n",
    "            post = words[(match_indexes[i]+1):(match_indexes[i]+size+1)]\n",
    "            \n",
    "            for i in range(0, len(post)):\n",
    "                match.append(post[i])\n",
    "            \n",
    "            out.append(match)\n",
    "    else:\n",
    "        out = [\"word not found\"]\n",
    "    \n",
    "    return out, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(text, word, size = 1):\n",
    "    '''\n",
    "    input:\n",
    "        text - the sentece/ text to perform algorithm\n",
    "        word - the key / or the word to find\n",
    "        size - the size of window to lookup, set=1 as default\n",
    "    \n",
    "    return:\n",
    "        matches - the set of words found after applying algo\n",
    "    \n",
    "    '''\n",
    "    con_lists, words = concordance(text, word, size)\n",
    "    \n",
    "    if (con_lists != [\"word not found\"]):\n",
    "        matches = set({})\n",
    "\n",
    "\n",
    "        for a_list in range(0, len(con_lists)):\n",
    "            pre_list, post_list = find_context(con_lists[a_list], word)\n",
    "\n",
    "\n",
    "            for b_words in range(0, len(words)):\n",
    "                ind = b_words\n",
    "                pre_match = True\n",
    "                post_match = True\n",
    "\n",
    "                for c in range(0, len(pre_list)):\n",
    "                    if (pre_list[c] == words[ind]):\n",
    "                        if (ind < (len(words) - 2)):\n",
    "                            ind += 1\n",
    "                        else:\n",
    "                            break\n",
    "                    else:\n",
    "                        pre_match = False\n",
    "                        break\n",
    "\n",
    "                if (ind < (len(words) - 2)):\n",
    "                    ind += 1\n",
    "\n",
    "                for c in range(0, len(post_list)):\n",
    "                    if (post_list[c] == words[ind]):\n",
    "                        if (ind < (len(words) - 2)):\n",
    "                            ind += 1\n",
    "                        else:\n",
    "                            break\n",
    "                    else:\n",
    "                        post_match = False\n",
    "                        break\n",
    "\n",
    "                if ((pre_match == True) and (post_match == True)):\n",
    "                    matches.add(words[b_words+len(pre_list)])\n",
    "\n",
    "\n",
    "\n",
    "        matches.discard(word)\n",
    "    else:\n",
    "        matches = \"No context for input word was found\"\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"cat was sleeping. a wolf was running. a parrot was chirping. a lion was roaring.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "{'lion', 'wolf', 'parrot'}\n"
     ]
    }
   ],
   "source": [
    "print(\"OUTPUT:\\n\")\n",
    "print(similar(text2, 'cat', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./similar.txt')\n",
    "\n",
    "f = f.readlines()\n",
    "count  = 0\n",
    "for i in f:\n",
    "    f[count] = f[count].strip()\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_ = ''\n",
    "for i in range(0, len(f)):\n",
    "    str_ += f[i]\n",
    "    str_ += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'she was similar to her he was not similar to her no that cat was likes to her that she was like to her he was not liker to her no but '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "{'like', 'liker'}\n"
     ]
    }
   ],
   "source": [
    "print(\"OUTPUT:\\n\")\n",
    "print(similar(str_, 'similar', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
