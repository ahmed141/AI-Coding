{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(text):\n",
    "    '''\n",
    "    Assumptions:\n",
    "        - I will deal abberviaions words as separte words e.g. Mr. Ahmed as 'Mr' and 'Ahmed'\n",
    "        - I will deal name with space within as seprate words e.g. Coca Cola as 'Coca' and 'Cola'\n",
    "        - I am assuming that my sentences/input text can only contain \" '.', ',', '?', and '!'. \n",
    "          however this concept can be extended in my code similarly as mentioned spatial characters are dealt.\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "        text - A string variable contains the text to be tokenized\n",
    "    returns:\n",
    "        words - list of strings, contains the list of tokenized words\n",
    "        \n",
    "    '''\n",
    "    words = text.replace('.',' . ').replace(',',' , ').replace('?', ' ? ').replace('!', ' ! ').split(' ')\n",
    "        \n",
    "    ept_count = 0\n",
    "    for i in range(0, len(words)):\n",
    "        if (words[i] == ''):\n",
    "            ept_count+=1\n",
    "    \n",
    "    \n",
    "    for i in range(0, ept_count):\n",
    "        words.remove('')\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_context(conc_list, word):\n",
    "    '''\n",
    "    This function returns that what was before and after the word in the list of strings\n",
    "    \n",
    "    inputs:\n",
    "        conc_list - the list of strings\n",
    "        word - the key OR the word to split list\n",
    "        \n",
    "    returns:\n",
    "        pre - the list of strings before 'word'\n",
    "        post - the list of strings after 'word'\n",
    "    '''\n",
    "    \n",
    "    centr = 0\n",
    "    \n",
    "    for i in range(0, len(conc_list)):\n",
    "        if (conc_list[i] == word):\n",
    "            centr = i\n",
    "            break\n",
    "    \n",
    "    pre = list(conc_list[:centr])\n",
    "    post = list(conc_list[(centr+1):])\n",
    "    \n",
    "    return pre, post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance(text, word, size = 3):\n",
    "    '''\n",
    "    input:\n",
    "        text - the sentece/ text to perform algorithm\n",
    "        word - the key / or the word to find\n",
    "        size - the size of window to lookup, set=3 as default\n",
    "    \n",
    "    return:\n",
    "        out - the result of concordance\n",
    "        words - the list of tokenized words\n",
    "    '''\n",
    "    \n",
    "    words = extract_words(text)\n",
    "    \n",
    "    match = False\n",
    "    match_indexes = []\n",
    "    \n",
    "    for i in range(0, len(words)):\n",
    "        if (words[i] == word):\n",
    "            match_indexes.append(i)\n",
    "            match = True\n",
    "    \n",
    "    # now match_indexes contains the indexes where the word is found\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    if (match == True):\n",
    "        for i in range(0, len(match_indexes)):\n",
    "            match = []\n",
    "            if((match_indexes[i]-size) >= 0):\n",
    "                pre = words[(match_indexes[i]-size):match_indexes[i]]\n",
    "            else:\n",
    "                pre = words[0:match_indexes[i]]\n",
    "                \n",
    "            for a in range(0, len(pre)):\n",
    "                match.append(pre[a])\n",
    "                \n",
    "            match.append(words[match_indexes[i]])\n",
    "            \n",
    "            post = words[(match_indexes[i]+1):(match_indexes[i]+size+1)]\n",
    "            \n",
    "            for i in range(0, len(post)):\n",
    "                match.append(post[i])\n",
    "            \n",
    "            out.append(match)\n",
    "    else:\n",
    "        out = [\"word not found\"]\n",
    "    \n",
    "    return out, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_indexes(win_words, target_words):\n",
    "    \n",
    "    indexes = []\n",
    "    last = 0\n",
    "    for i in range(0, len(target_words)):\n",
    "        for j in range(last, len(win_words)):\n",
    "            if(target_words[i] == win_words[j]):\n",
    "                indexes.append(j)\n",
    "                last = j\n",
    "                \n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_similar(text, word, window_size, matches_size):\n",
    "    '''\n",
    "    input:\n",
    "        text - The sentence / text to perform algorithm\n",
    "        word - The key/word to find context\n",
    "        window_size - Window size for context lookup\n",
    "        matches_size - Number of matches to satisfy approximation\n",
    "    returns:\n",
    "        out - Set containing all words with approximated context as ‘word’\n",
    "    '''\n",
    "    \n",
    "    conc_lists, words = concordance(text, word, window_size)\n",
    "    \n",
    "    # print(\"conc_lists:\\t\\t\" + str(conc_lists) + \"\\n\\n\")\n",
    "    \n",
    "    if (conc_lists != [\"word not found\"]):\n",
    "        matches = set({})\n",
    "\n",
    "        for a_conc_idx in range(0, len(conc_lists)):\n",
    "            pre_list, post_list = find_context(conc_lists[a_conc_idx], word)\n",
    "\n",
    "            for b_word_idx in range(0, len(words)): # iteraing all words\n",
    "\n",
    "                for c_pre_win in range(0, window_size):\n",
    "                    pre_win_start = b_word_idx\n",
    "                    pre_win_end = b_word_idx + c_pre_win\n",
    "\n",
    "                    pre_win_words = words[pre_win_start:pre_win_end]\n",
    "\n",
    "                    pre_match_indices = match_indexes(pre_win_words, pre_list) #returns list of matched indexes\n",
    "                    \n",
    "                    #print()\n",
    "                    \n",
    "                    if (len(pre_match_indices) >= matches_size):\n",
    "                        center_start = pre_match_indices.index(max(pre_match_indices)) # max index in list\n",
    "                        center_start += pre_win_start\n",
    "\n",
    "                        for d_post_win in range(0, window_size):\n",
    "                            post_win_start = center_start + 1\n",
    "                            post_win_end = post_win_start + d_post_win\n",
    "\n",
    "                            post_win_words = words[post_win_start:post_win_end]\n",
    "\n",
    "                            post_match_indicies = match_indexes(post_win_words, post_list)\n",
    "\n",
    "                            if(len(post_match_indicies) >= matches_size):\n",
    "                                center_end = post_match_indicies.index(min(post_match_indicies)) # min index in list\n",
    "                                center_end += post_win_start\n",
    "\n",
    "                                matches.update(words[center_start:(center_end+1)])\n",
    "\n",
    "        matches.discard(word)\n",
    "    else:\n",
    "        matches = \"No context for input word was found\"\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"a litte mouse was being chased by a cat, who we bought yesterday who was grey. there was a wolf who was running.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "{'a', 'chased', 'wolf', 'was', '.', 'there', 'by'}\n"
     ]
    }
   ],
   "source": [
    "print(\"OUTPUT:\\n\\n\" + str(approximate_similar(text3, 'cat', 6, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./approximate similar with context.txt')\n",
    "\n",
    "f = f.readlines()\n",
    "count  = 0\n",
    "for i in f:\n",
    "    f[count] = f[count].strip()\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there is not was a cat was running after a rat',\n",
       " 'there was tiger after rat',\n",
       " 'not a was there lion after running rat a',\n",
       " 'fox after running a rat',\n",
       " 'not there elephant']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_ = ''\n",
    "for i in range(0, len(f)):\n",
    "    str_ += f[i]\n",
    "    str_ += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there is not was a cat was running after a rat there was tiger after rat not a was there lion after running rat a fox after running a rat not there elephant '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "{'a', 'after', 'fox', 'running', 'was', 'rat', 'tiger', 'is', 'not', 'there'}\n"
     ]
    }
   ],
   "source": [
    "print(\"OUTPUT:\\n\")\n",
    "print(approximate_similar(str_, 'cat', 6, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
