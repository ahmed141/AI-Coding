{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading 'nospaces' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"../data/50_spaces.txt\"\n",
    "f_words = codecs.open(file1, \"r\", \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = f_words.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_words = text_words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(space_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_sentences = []\n",
    "for i in space_words:\n",
    "    spaced_sentences.append(i.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['دکھوں',\n",
       " 'اور',\n",
       " 'نیرنگ',\n",
       " 'انتہاؤں',\n",
       " 'کا',\n",
       " 'دارومدار',\n",
       " 'پرخلوص',\n",
       " 'پالیسیوں',\n",
       " 'پر',\n",
       " 'ہے']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaced_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading 'wordslist' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3 = \"../data/wordlist.txt\"\n",
    "f_words = codecs.open(file3, \"r\", \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = f_words.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordslist = text_words.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Functions_Defs.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading '50_nospaces' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = \"../data/50_nospaces.txt\"\n",
    "f_words = codecs.open(file2, \"r\", \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = f_words.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nospace_words = text_words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nospace_sentences = []\n",
    "for i in nospace_words:\n",
    "    nospace_sentences.append(MaxMatch(i, wordslist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nospace_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using functions for MED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:\t ['چولی', 'کاجو', 'ڑ', 'ا', 'پہنتے', 'ہوئے', 'بیٹھو', 'تو', 'لائیو', 'اپھارہ', 'برسنے', 'میں', 'ٹھہراؤ', 'آج', 'ا', 'ت', 'ا', 'ہے']\n",
      "target:\t ['چولی', 'کا', 'جوڑا', 'پہنتے', 'ہوئے', 'بیٹھو', 'تو', 'لائیو', 'اپھارہ', 'برسنے', 'میں', 'ٹھہراؤ', 'آ', 'جاتا', 'ہے'] \n",
      "\n",
      "Total MED:\t\t\t 86\n",
      "Total Insertions:\t\t 24\n",
      "Total Deletions:\t\t 24\n",
      "Total Substitutions:\t\t 19\n"
     ]
    }
   ],
   "source": [
    "index = 49\n",
    "print(\"Source:\\t\", nospace_sentences[index])\n",
    "print(\"target:\\t\", spaced_sentences[index], \"\\n\")\n",
    "\n",
    "out1 = char_based(nospace_sentences[index], spaced_sentences[index])\n",
    "print(\"Total MED:\\t\\t\\t\", out1['total_MED'])\n",
    "print(\"Total Insertions:\\t\\t\", out1['total_I'])\n",
    "print(\"Total Deletions:\\t\\t\", out1['total_D'])\n",
    "print(\"Total Substitutions:\\t\\t\", out1['total_S'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:\t ['چولی', 'کاجو', 'ڑ', 'ا', 'پہنتے', 'ہوئے', 'بیٹھو', 'تو', 'لائیو', 'اپھارہ', 'برسنے', 'میں', 'ٹھہراؤ', 'آج', 'ا', 'ت', 'ا', 'ہے']\n",
      "target:\t ['چولی', 'کا', 'جوڑا', 'پہنتے', 'ہوئے', 'بیٹھو', 'تو', 'لائیو', 'اپھارہ', 'برسنے', 'میں', 'ٹھہراؤ', 'آ', 'جاتا', 'ہے'] \n",
      "\n",
      "MED:\t\t\t\t 11\n",
      "Insertions:\t\t\t 0\n",
      "Deletions:\t\t\t 3\n",
      "Substitutions:\t\t\t 4\n",
      "\n",
      "\n",
      "Word-to-Error ratio:\t\t 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "index = 49\n",
    "print(\"Source:\\t\", nospace_sentences[index])\n",
    "print(\"target:\\t\", spaced_sentences[index], \"\\n\")\n",
    "\n",
    "out2 = word_based(nospace_sentences[index], spaced_sentences[index])\n",
    "print(\"MED:\\t\\t\\t\\t\", out2['MED'])\n",
    "print(\"Insertions:\\t\\t\\t\", out2['I'])\n",
    "print(\"Deletions:\\t\\t\\t\", out2['D'])\n",
    "print(\"Substitutions:\\t\\t\\t\", out2['S'])\n",
    "print(\"\\n\\nWord-to-Error ratio:\\t\\t\", out2['WER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average WER of entire test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER:\t\t\t 0.09767758711876359\n"
     ]
    }
   ],
   "source": [
    "print(\"Average WER:\\t\\t\\t\", avg_WER(nospace_sentences, spaced_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
